# Awesome Training Free MLLMs



## Papers



| Year | Title                                    | Venue |                    Paper                     | Code |
| ---- | ---------------------------------------- | :---: | :------------------------------------------: | :--: |
| 2025 | **See what you are told: Visual attention sink in large multimodal models** | ICLR'25 | [Link](https://arxiv.org/pdf/2503.03321?) |  [Code](https://github.com/seilk/VisAttnSink)  |
| 2025 |  **Mllms know where to look: Training-free perception of small visual details with multimodal llms**            |   ICLR'25    |   [Link](https://arxiv.org/pdf/2502.17422)       |  [Code](https://github.com/saccharomycetes/mllms_know)    |
| 2025 | **Stop Looking for “Important Tokens” in Multimodal Language Models: Duplication Matters More**| Arxiv | [Link](https://arxiv.org/pdf/2502.11494?) | [Code](https://github.com/ZichenWen1/DART)|




